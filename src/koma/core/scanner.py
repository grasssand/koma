import logging
import os
import shutil
import tempfile
from collections.abc import Callable, Generator
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

from natsort import natsorted

from koma.config import ExtensionsConfig
from koma.core.archive import ArchiveHandler
from koma.core.image_processor import ImageProcessor

logger = logging.getLogger(__name__)


@dataclass
class ScanResult:
    to_convert: list[Path] = field(default_factory=list)
    to_copy: list[Path] = field(default_factory=list)
    ads: list[Path] = field(default_factory=list)
    junk: list[Path] = field(default_factory=list)
    processed_archives: int = 0


class Scanner:
    def __init__(
        self,
        input_dir: Path,
        ext_config: ExtensionsConfig,
        image_processor: ImageProcessor,
    ):
        """
        åˆå§‹åŒ–æ‰«æå™¨

        Args:
            input_dir: æ‰«ææ ¹ç›®å½•
            ext_config: æ‰©å±•åé…ç½®
            image_processor: å›¾åƒå¤„ç†å™¨
        """
        self.input_dir = Path(input_dir)
        self.ext_config = ext_config
        self.image_processor = image_processor
        self.archive_handler = ArchiveHandler(self.ext_config)

        self.supported_img = self.ext_config.all_supported_img
        self.valid_extensions = (
            self.supported_img | self.ext_config.archive | self.ext_config.document
        )

    def run(
        self,
        options: dict[str, Any] | None = None,
        progress_callback: Callable[[int, int, str], None] | None = None,
    ) -> Generator[tuple[Path, ScanResult], None, None]:
        options = options or {}
        enable_ad_scan = options.get("enable_ad_scan", False)
        enable_archive_scan = options.get("enable_archive_scan", False)
        out_dir_str = options.get("archive_out_path")
        exclude_path = Path(out_dir_str).resolve() if out_dir_str else None

        try:
            for root, dirs, files in os.walk(self.input_dir):
                root_path = Path(root).resolve()
                if exclude_path:
                    try:
                        if root_path == exclude_path or root_path.is_relative_to(
                            exclude_path
                        ):
                            dirs[:] = []
                            continue
                    except ValueError:
                        pass

                # æ’é™¤éšè—æ–‡ä»¶å¤¹
                dirs[:] = [d for d in dirs if not d.startswith(".")]

                root_path = Path(root)
                result = ScanResult()
                files = natsorted(files)

                image_candidates = []

                for f in files:
                    f_path = root_path / f

                    # å‹ç¼©åŒ…æ‰«æ
                    if enable_archive_scan and self._is_archive(f_path):
                        if self._process_archive(f_path, options):
                            result.processed_archives += 1
                        continue

                    # å¸¸è§„æ–‡ä»¶æ‰«æ
                    is_junk_file = self._is_junk(f_path)

                    if is_junk_file:
                        result.junk.append(f_path)
                        continue

                    if f_path.suffix.lower() in self.supported_img:
                        image_candidates.append(f)

                # å¹¿å‘Šæ£€æµ‹
                confirmed_ads = set()
                if image_candidates and enable_ad_scan:
                    confirmed_ads = self._detect_ads_in_folder(
                        root_path, image_candidates
                    )

                # ç»“æœå½’ç±»
                self._categorize_files(
                    root_path, image_candidates, confirmed_ads, result
                )

                if (
                    result.to_convert
                    or result.to_copy
                    or result.ads
                    or result.junk
                    or result.processed_archives > 0
                ):
                    yield root_path, result

        finally:
            if progress_callback:
                progress_callback(1, 1, "æ‰«æåˆ†æå®Œæˆ")

    def _process_archive(self, archive_path: Path, options: dict) -> bool:
        """å¤„ç†å•ä¸ªå‹ç¼©åŒ…ï¼šæ£€æŸ¥ç©ºé—´ -> è§£å‹ -> æ¸…ç† -> é‡æ‰“åŒ…"""
        output_dir = options.get("archive_out_path")
        if not output_dir:
            return False

        try:
            required_space = archive_path.stat().st_size * 2.5
            temp_base = Path(tempfile.gettempdir())
            free_space = shutil.disk_usage(temp_base).free

            if free_space < required_space:
                logger.error(
                    f"âŒ è·³è¿‡å‹ç¼©åŒ… {archive_path.name}: ç£ç›˜ç©ºé—´ä¸è¶³ "
                    f"(éœ€è¦ {required_space / 1024 / 1024:.1f}MB, å‰©ä½™ {free_space / 1024 / 1024:.1f}MB)"
                )
                return False
        except Exception:
            pass

        try:
            with tempfile.TemporaryDirectory(prefix="koma_extract_") as temp_dir:
                temp_root = Path(temp_dir)

                # è§£å‹
                content_root = self.archive_handler.extract(archive_path, temp_root)

                # æ¸…ç†
                deleted_count = self._clean_directory_recursive(
                    content_root, check_ads=options.get("enable_ad_scan", False)
                )
                if deleted_count == 0:
                    logger.info(f"â© è·³è¿‡å¹²å‡€å‹ç¼©åŒ…: {archive_path.name}")
                    return False

                logger.info(f"ğŸš« å‘ç°æ‚é¡¹æˆ–å¹¿å‘Š: {archive_path.name}")

                # é‡æ‰“åŒ… æˆ– å¤åˆ¶
                dest_base = Path(output_dir) / archive_path.stem

                if options.get("repack", True):
                    fmt = options.get("pack_format", "zip")
                    final_path = dest_base.with_suffix(f".{fmt}")

                    self.archive_handler.pack(
                        content_root, final_path, fmt=fmt, level="normal"
                    )
                    logger.info(
                        f"ğŸ“¦ å·²é‡æ‰“åŒ… (æ¸…ç† {deleted_count} ä¸ªæ–‡ä»¶): {archive_path.name} -> {final_path}"
                    )
                else:
                    if not dest_base.exists():
                        shutil.move(str(content_root), str(dest_base))
                        logger.info(
                            f"âœ… å·²ç§»åŠ¨ (æ¸…ç† {deleted_count} ä¸ªæ–‡ä»¶): {archive_path.name} -> {dest_base}"
                        )
                    else:
                        shutil.copytree(content_root, dest_base, dirs_exist_ok=True)
                        logger.info(
                            f"âœ… å·²åˆå¹¶ (æ¸…ç† {deleted_count} ä¸ªæ–‡ä»¶): {archive_path.name} -> {dest_base}"
                        )

                return True

        except OSError as e:
            if e.errno == 28:
                logger.critical(f"â›” å¤„ç† {archive_path.name} æ—¶ç£ç›˜ç©ºé—´è€—å°½ï¼")
            else:
                logger.error(f"å¤„ç†å‹ç¼©åŒ…IOé”™è¯¯ {archive_path}: {e}")
            return False

        except Exception as e:
            logger.error(f"å¤„ç†å‹ç¼©åŒ…å¤±è´¥ {archive_path}: {e}")
            return False

    def _clean_directory_recursive(self, target_dir: Path, check_ads: bool) -> int:
        """é€’å½’æ¸…ç†ä¸´æ—¶ç›®å½•ä¸­çš„åƒåœ¾å’Œå¹¿å‘Š"""
        deleted_count = 0

        for root, _, files in os.walk(target_dir):
            root_path = Path(root)
            files = natsorted(files)

            image_candidates = []

            # åˆ æ‚é¡¹
            for f in files:
                f_path = root_path / f
                if self._is_junk(f_path):
                    try:
                        os.remove(f_path)
                        deleted_count += 1
                        logger.debug(f"[TempClean] åˆ é™¤æ‚é¡¹: {f}")
                    except OSError:
                        pass
                elif f_path.suffix.lower() in self.supported_img:
                    image_candidates.append(f)

            # åˆ å¹¿å‘Š
            if check_ads and image_candidates:
                ads = self._detect_ads_in_folder(root_path, image_candidates)
                for ad in ads:
                    try:
                        os.remove(root_path / ad)
                        deleted_count += 1
                        logger.debug(f"[TempClean] åˆ é™¤å¹¿å‘Š: {ad}")
                    except OSError:
                        pass

        return deleted_count

    def _is_junk(self, path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ‚é¡¹æ–‡ä»¶"""
        name = path.name
        suffix = path.suffix.lower()

        # éšè—æ–‡ä»¶
        if name.startswith("."):
            return True

        # ç™½åå•æ–‡ä»¶
        if name.lower() in self.ext_config.misc_whitelist:
            return False

        return suffix not in self.valid_extensions

    def _is_archive(self, path: Path) -> bool:
        return path.suffix.lower() in self.ext_config.archive

    def _detect_ads_in_folder(self, root: Path, images: list[str]) -> set[str]:
        """å€’åºæ£€æµ‹æ–‡ä»¶å¤¹å†…çš„å¹¿å‘Šå›¾ç‰‡"""
        confirmed = set()

        # å€’åºæ£€æŸ¥æœ€åå‡ å¼ å›¾
        for i in range(len(images) - 1, -1, -1):
            img_name = images[i]
            img_path = root / img_name
            try:
                info = self.image_processor.analyze(img_path)
            except Exception:
                continue

            # å¦‚æœæ˜¯æ­£å¸¸æ¼«ç”»é¡µï¼ˆéåŠ¨å›¾ã€éç°åº¦ç­‰ï¼‰ï¼Œåœæ­¢æ£€æµ‹
            # ç®€å•å¯å‘å¼ï¼šå¦‚æœä¸æ˜¯äºŒç»´ç å¹¿å‘Šä¸”å†…å®¹çœ‹èµ·æ¥æ­£å¸¸ï¼Œå°±è®¤ä¸ºåˆ°åº•äº†
            if info.is_animated:
                break

            if self.image_processor.has_ad_qrcode(img_path):
                confirmed.add(img_name)
            else:
                # é‡åˆ°ç¬¬ä¸€å¼ éå¹¿å‘Šå›¾ï¼Œåœæ­¢å€’åºæ‰«æ
                break

        return confirmed

    def _categorize_files(
        self, root: Path, images: list[str], ads: set[str], result: ScanResult
    ):
        for f_name in images:
            file_path = root / f_name
            suffix = file_path.suffix.lower()

            if f_name in ads:
                result.ads.append(file_path)
            elif suffix in self.ext_config.convert:
                result.to_convert.append(file_path)
            elif suffix in self.ext_config.passthrough:
                result.to_copy.append(file_path)
